# -*- coding: utf-8 -*-
"""DD_Preprocess.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cj-MleIzhUKR4b7Pd3SOOQiPxiXKkQRh
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install nltk
nltk.download('all')
nltk.download('stopwords')
nltk.download('punkt')
import nltk
import spacy
import string
import re
import keras
import numpy as np
import pandas as pd
from pandas import read_csv
import sklearn.metrics as sm
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,accuracy_score,precision_score,recall_score,f1_score

from google.colab import drive
drive.mount('/content/drive')

dataset=read_csv("/content/drive/MyDrive/ moynul/Deprassion_Detection_final_data - Deprassion_Detection_final_data.csv",encoding="UTF-8")
dataset.head()

dataset=dataset.drop_duplicates()
dataset.shape

len(dataset.Class.value_counts())

dataset.Class.unique()

dataset.isnull().sum()

print("Total Reviews:",len(dataset),
      "\nTotal happy Reviews:",len(dataset[dataset.Class =='happy']),
      "\nTotal sad Reviews:",len(dataset[dataset.Class=='sad']),
      "\nTotal angry Reviews:",len(dataset[dataset.Class =='angry']),
      "\nTotal anxiety Reviews:",len(dataset[dataset.Class =='anxiety']))

sns.countplot(dataset['Class'])

from wordcloud import WordCloud 
# Plot the Word Cloud
allWords = ' '.join([comnt for comnt in dataset['Text']])
wordCloud = WordCloud(width =1000, height =800, random_state = 21, max_font_size = 119).generate(allWords)

plt.imshow(wordCloud, interpolation = "bilinear")
plt.axis('off')
plt.show()

"""**Preorocesss Section**"""

from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer
stemmer=nltk.SnowballStemmer('english')
STOPWORDS=stopwords.words('english')
PUNCT_TO_REMOVE = string.punctuation

def remove_emoji(string):
    emoji_pattern = re.compile("["
                           u"\U0001F600-\U0001F64F"  # emoticons
                           u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                           u"\U0001F680-\U0001F6FF"  # transport & map symbols
                           u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           u"\U00002702-\U000027B0"
                           u"\U000024C2-\U0001F251"
                           "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', string)
dataset['Text'] = dataset['Text'].apply(remove_emoji)

def clean_text(text):
    
    text = word_tokenize(text)                                                     # tokenize
    text = str(text).lower()                                                       # converting to lower case
    text = re.sub(r'@\S+|http\S+|www.\S+|\n','',text)                              # removing mentions and links
    text = re.sub(r'[^A-Za-z0-9\s]+', '', text)                                    # removing special characters 
    text = [stemmer.stem(word) for word in text.split(' ')]                        # stem words 
    text = " ".join([word for word in text if word not in STOPWORDS])              # remove stopwords
    text = text.strip()                                                            # remove extra spaces from start and end of string
    text = text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))                  # remove puncuation
     
    return text

dataset['clean_data'] = dataset['Text'].apply(clean_text)

dataset.head(10)

dataset=dataset[['clean_data','Class']]
dataset.head(5)

"""**Preprocess labbelling class to nuemeric**"""

from sklearn.preprocessing import LabelEncoder
dataset["Class"] = LabelEncoder().fit_transform(dataset["Class"])
dataset["Class"]

"""**Applying only CountVectorizer**"""

x= dataset.clean_data.values[:10424]

y= dataset.Class.values[:10424]

from sklearn.feature_extraction.text import CountVectorizer

# Create a Vectorizer Object
vectorizer = CountVectorizer()
 
vectorizer.fit(x)
 
# Printing the identified Unique words along with their indices
# print("Vocabulary: ", vectorizer.vocabulary_)
 
# Encode the Document
vector = vectorizer.transform(x)
 
# Summarizing the Encoded Texts
# print("Encoded Document is:")
print(vector.toarray())

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(vector, y, test_size=0.2, shuffle=True, random_state=100)

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.linear_model import SGDClassifier

model = LogisticRegression()
model.fit(X_train, y_train)
model.score( X_test,y_test)

model = DecisionTreeClassifier()
model.fit(X_train, y_train)
model.score( X_test,y_test)

model = RandomForestClassifier()
model.fit(X_train, y_train)
model.score( X_test,y_test)

model = MultinomialNB()
model.fit(X_train, y_train)
model.score( X_test,y_test)

model = KNeighborsClassifier()
model.fit(X_train, y_train)
model.score( X_test,y_test)

model =SVC()
model.fit(X_train, y_train)
model.score( X_test,y_test)

model =SGDClassifier()
model.fit(X_train, y_train)
model.score( X_test,y_test)





""" **Applying CV and tf-idf features**"""

from sklearn.model_selection import train_test_split

X = dataset.clean_data
y = dataset.Class
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)

X_train.shape,X_test.shape,y_train.shape,y_test.shape

from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfTransformer

lr = Pipeline([('vect', CountVectorizer()),
               ('tfidf', TfidfTransformer()),
               ('clf', LogisticRegression()),
              ])

lr.fit(X_train,y_train)
y_pred1 = lr.predict(X_test)

print("Accuracy: {0:.2%}".format(accuracy_score(y_pred1,y_test)))

from sklearn.metrics import classification_report
print('\nClassification Report\n')
print(classification_report(y_test,y_pred1))

from sklearn.tree import DecisionTreeClassifier


decisiontreeclassifier = Pipeline([('vect', CountVectorizer()),
               ('tfidf', TfidfTransformer()),
               ('clf', DecisionTreeClassifier()),
              ])
decisiontreeclassifier.fit(X_train, y_train)

y_pred = decisiontreeclassifier.predict(X_test)

print("Accuracy: {0:.2%}".format(accuracy_score(y_pred,y_test)))

from sklearn.metrics import classification_report
print('\nClassification Report\n')
print(classification_report(y_test,y_pred))

from sklearn.ensemble import RandomForestClassifier

randomforestclassifier = Pipeline([('vect', CountVectorizer()),
               ('tfidf', TfidfTransformer()),
               ('clf', RandomForestClassifier()),
              ])
randomforestclassifier.fit(X_train, y_train)

y_pred = randomforestclassifier.predict(X_test)

print("Accuracy: {0:.2%}".format(accuracy_score(y_pred,y_test)))

from sklearn.metrics import classification_report
print('\nClassification Report\n')
print(classification_report(y_test,y_pred))

from sklearn.naive_bayes import MultinomialNB


naivebayes = Pipeline([('vect', CountVectorizer()),
               ('tfidf', TfidfTransformer()),
               ('clf', MultinomialNB()),
              ])
naivebayes.fit(X_train, y_train)

y_pred = naivebayes.predict(X_test)

print("Accuracy: {0:.2%}".format(accuracy_score(y_pred,y_test)))

from sklearn.metrics import classification_report
print('\nClassification Report\n')
print(classification_report(y_test,y_pred))

from sklearn.neighbors import KNeighborsClassifier

KNeighborsClassifier = Pipeline([('vect', CountVectorizer()),
               ('tfidf', TfidfTransformer()),
               ('clf', KNeighborsClassifier()),
              ])
KNeighborsClassifier.fit(X_train, y_train)

y_pred = KNeighborsClassifier.predict(X_test)

print("Accuracy: {0:.2%}".format(accuracy_score(y_pred,y_test)))

from sklearn.metrics import classification_report
print('\nClassification Report\n')
print(classification_report(y_test,y_pred))

from sklearn.svm import SVC

SVC = Pipeline([('vect', CountVectorizer()),
               ('tfidf', TfidfTransformer()),
               ('clf', SVC()),
              ])
SVC.fit(X_train, y_train)

y_pred = SVC.predict(X_test)

print("Accuracy: {0:.2%}".format(accuracy_score(y_pred,y_test)))

from sklearn.metrics import classification_report
print('\nClassification Report\n')
print(classification_report(y_test,y_pred))